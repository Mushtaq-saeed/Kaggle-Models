import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Load data
# Download the data file and then uncomment this 2 lines of code otherwise it will give error
# train_data = pd.read_csv('train.csv')
# test_data = pd.read_csv('test.csv')
Y_train = train_data['Survived']

# Feature engineering function
def process_raw_data(data):
    # Fill missing values
    data['Age'] = data['Age'].fillna(data.groupby(['Pclass', 'Sex'])['Age'].transform('median'))
    data['Embarked'] = data['Embarked'].fillna('S')
    data['Fare'] = data['Fare'].fillna(data.groupby(['Parch', 'SibSp', 'Pclass'])['Fare'].transform('median'))

    # Create new features
    data['Deck'] = data['Pclass'].map({1: 'ABC', 2: 'DE', 3: 'FG'})
    data['Family_Size'] = data['SibSp'] + data['Parch'] + 1
    data['Title'] = data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())
    data['Title'] = data['Title'].replace(['Miss', 'Mrs', 'Mlle', 'Lady', 'Dona'], 'Miss/Mrs/Ms')
    data['Title'] = data['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')
    data['Title'] = np.where((data['Sex'] == 'male') & (data['Age'] < 26 ), 'Master', data['Title'])
    data['Is_married'] = np.where((data['Sex'] == 'female') & (data['Title'] == 'Miss/Mrs/Ms') & (data['Name'].str.contains('Mrs')), 1, 0)

    # Drop unnecessary columns
    data = data.drop(['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch'], axis=1)

    return data

# Process data
train_data = process_raw_data(train_data)
train_data = train_data.drop(['Survived', 'PassengerId'], axis=1)
test_data = process_raw_data(test_data)

# Preprocessing
numeric_features = ['Age', 'Fare', 'Pclass', 'Family_Size', 'Is_married']
categorical_features = ['Embarked', 'Deck', 'Sex', 'Title']

numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

X_train_processed = preprocessor.fit_transform(train_data)
X_test_processed = preprocessor.transform(test_data)

# Define and compile the model
model = Sequential([
    Dense(units=64, activation='relu', input_shape=(X_train_processed.shape[1],)),
    Dense(units=32, activation='relu'),
    Dense(units=16, activation='relu'),
    Dense(units=1, activation='sigmoid')
])

model.compile(optimizer=Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(X_train_processed, Y_train, epochs=50, validation_split=0.2)

# Evaluate the model
train_loss, train_accuracy = model.evaluate(X_train_processed, Y_train)
print(f"Training Accuracy: {train_accuracy}")

# Make predictions on test data
predictions = model.predict(X_test_processed)
predictions = (predictions > 0.5).astype(int)

# Prepare submission
passenger_ids = test_data['PassengerId']
submission = pd.DataFrame({
    'PassengerId': passenger_ids,
    'Survived': predictions.flatten()
})
submission.to_csv('submission.csv', index=False)
print("Submission saved successfully.")
print(submission[['PassengerId', 'Survived']])
